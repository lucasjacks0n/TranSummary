{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b057f549-3657-4a0b-b1dd-8f0a65d03599",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "failed to find libmagic.  Check your installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmagic\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmimetypes\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/videoextractor/packages/api/venv/lib/python3.11/site-packages/magic/__init__.py:209\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\u001b[38;5;241m.\u001b[39mfrom_descriptor(fd)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loader\n\u001b[0;32m--> 209\u001b[0m libmagic \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m magic_t \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorcheck_null\u001b[39m(result, func, args):\n",
      "File \u001b[0;32m~/Workspace/videoextractor/packages/api/venv/lib/python3.11/site-packages/magic/loader.py:49\u001b[0m, in \u001b[0;36mload_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;66;03m# It is better to raise an ImportError since we are importing magic module\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to find libmagic.  Check your installation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: failed to find libmagic.  Check your installation"
     ]
    }
   ],
   "source": [
    "# Prediction interface for Cog ⚙️\n",
    "from typing import Any, List\n",
    "import base64\n",
    "import contextlib\n",
    "import datetime\n",
    "import json\n",
    "import magic\n",
    "import mimetypes\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import torch\n",
    "import wave\n",
    "import re\n",
    "\n",
    "from cog import BasePredictor, BaseModel, Input, File, Path\n",
    "from faster_whisper import WhisperModel\n",
    "from pyannote.audio import Pipeline\n",
    "print('here')\n",
    "\n",
    "class Output(BaseModel):\n",
    "    segments: list\n",
    "\n",
    "\n",
    "class Predictor(BasePredictor):\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Load the model into memory to make running multiple predictions efficient\"\"\"\n",
    "        model_name = \"large-v2\"\n",
    "        self.model = WhisperModel(\n",
    "            model_name,\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "            compute_type=\"float16\")\n",
    "        self.diarization_model = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.0\",\n",
    "            use_auth_token=\"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\").to(\n",
    "                torch.device(\"cuda\"))\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        file_string: str = Input(\n",
    "            description=\"Either provide: Base64 encoded audio file,\",\n",
    "            default=None),\n",
    "        file_url: str = Input(\n",
    "            description=\"Or provide: A direct audio file URL\", default=None),\n",
    "        file: Path = Input(description=\"Or an audio file\", default=None),\n",
    "        group_segments: bool = Input(\n",
    "            description=\n",
    "            \"Group segments of same speaker shorter apart than 2 seconds\",\n",
    "            default=True),\n",
    "        num_speakers: int = Input(description=\"Number of speakers\",\n",
    "                                  ge=1,\n",
    "                                  le=50,\n",
    "                                  default=2),\n",
    "        prompt: str = Input(description=\"Prompt, to be used as context\",\n",
    "                            default=\"Some people speaking.\"),\n",
    "        offset_seconds: int = Input(\n",
    "            description=\"Offset in seconds, used for chunked inputs\",\n",
    "            default=0,\n",
    "            ge=0)\n",
    "    ) -> Output:\n",
    "        \"\"\"Run a single prediction on the model\"\"\"\n",
    "        # Check if either filestring, filepath or file is provided, but only 1 of them\n",
    "        \"\"\" if sum([file_string is not None, file_url is not None, file is not None]) != 1:\n",
    "            raise RuntimeError(\"Provide either file_string, file or file_url\") \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Generate a temporary filename\n",
    "            temp_wav_filename = f\"temp-{time.time_ns()}.wav\"\n",
    "\n",
    "            if file is not None:\n",
    "                subprocess.run([\n",
    "                    'ffmpeg', '-i', file, '-ar', '16000', '-ac', '1', '-c:a',\n",
    "                    'pcm_s16le', temp_wav_filename\n",
    "                ])\n",
    "\n",
    "            elif file_url is not None:\n",
    "                response = requests.get(file_url)\n",
    "                temp_audio_filename = f\"temp-{time.time_ns()}.audio\"\n",
    "                with open(temp_audio_filename, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "\n",
    "                subprocess.run([\n",
    "                    'ffmpeg', '-i', temp_audio_filename, '-ar', '16000', '-ac',\n",
    "                    '1', '-c:a', 'pcm_s16le', temp_wav_filename\n",
    "                ])\n",
    "\n",
    "                if os.path.exists(temp_audio_filename):\n",
    "                    os.remove(temp_audio_filename)\n",
    "            elif file_string is not None:\n",
    "                audio_data = base64.b64decode(\n",
    "                    file_string.split(',')[1] if ',' in\n",
    "                    file_string else file_string)\n",
    "                temp_audio_filename = f\"temp-{time.time_ns()}.audio\"\n",
    "                with open(temp_audio_filename, 'wb') as f:\n",
    "                    f.write(audio_data)\n",
    "\n",
    "                subprocess.run([\n",
    "                    'ffmpeg', '-i', temp_audio_filename, '-ar', '16000', '-ac',\n",
    "                    '1', '-c:a', 'pcm_s16le', temp_wav_filename\n",
    "                ])\n",
    "\n",
    "                if os.path.exists(temp_audio_filename):\n",
    "                    os.remove(temp_audio_filename)\n",
    "\n",
    "            segments = self.speech_to_text(temp_wav_filename, num_speakers,\n",
    "                                           prompt, offset_seconds,\n",
    "                                           group_segments)\n",
    "\n",
    "            print(f'done with inference')\n",
    "            # Return the results as a JSON object\n",
    "            return Output(segments=segments)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Error Running inference with local model\", e)\n",
    "\n",
    "        finally:\n",
    "            # Clean up\n",
    "            if os.path.exists(temp_wav_filename):\n",
    "                os.remove(temp_wav_filename)\n",
    "\n",
    "    def convert_time(self, secs, offset_seconds=0):\n",
    "        return datetime.timedelta(seconds=(round(secs) + offset_seconds))\n",
    "\n",
    "    def speech_to_text(self,\n",
    "                       audio_file_wav,\n",
    "                       num_speakers=2,\n",
    "                       prompt=\"People takling.\",\n",
    "                       offset_seconds=0,\n",
    "                       group_segments=True):\n",
    "        time_start = time.time()\n",
    "\n",
    "        # Transcribe audio\n",
    "        print(\"Starting transcribing\")\n",
    "        options = dict(vad_filter=True,\n",
    "                       initial_prompt=prompt,\n",
    "                       word_timestamps=True)\n",
    "        segments, _ = self.model.transcribe(audio_file_wav, **options)\n",
    "        segments = list(segments)\n",
    "        segments = [{\n",
    "            'start':\n",
    "            float(s.start + offset_seconds),\n",
    "            'end':\n",
    "            float(s.end + offset_seconds),\n",
    "            'text':\n",
    "            s.text,\n",
    "            'words': [{\n",
    "                'start': float(w.start + offset_seconds),\n",
    "                'end': float(w.end + offset_seconds),\n",
    "                'word': w.word\n",
    "            } for w in s.words]\n",
    "        } for s in segments]\n",
    "\n",
    "        time_transcribing_end = time.time()\n",
    "        print(\n",
    "            f\"Finished with transcribing, took {time_transcribing_end - time_start:.5} seconds\"\n",
    "        )\n",
    "        diarization = self.diarization_model(audio_file_wav,\n",
    "                                             num_speakers=num_speakers)\n",
    "\n",
    "        time_diraization_end = time.time()\n",
    "        print(\n",
    "            f\"Finished with diarization, took {time_diraization_end - time_transcribing_end:.5} seconds\"\n",
    "        )\n",
    "\n",
    "        # Initialize variables to keep track of the current position in both lists\n",
    "        margin = 0.1  # 0.1 seconds margin\n",
    "\n",
    "        # Initialize an empty list to hold the final segments with speaker info\n",
    "        final_segments = []\n",
    "\n",
    "        diarization_list = list(diarization.itertracks(yield_label=True))\n",
    "        speaker_idx = 0\n",
    "        n_speakers = len(diarization_list)\n",
    "\n",
    "        # Iterate over each segment\n",
    "        for segment in segments:\n",
    "            segment_start = segment['start'] + offset_seconds\n",
    "            segment_end = segment['end'] + offset_seconds\n",
    "            segment_text = []\n",
    "            segment_words = []\n",
    "\n",
    "            # Iterate over each word in the segment\n",
    "            for word in segment['words']:\n",
    "                word_start = word['start'] + offset_seconds - margin\n",
    "                word_end = word['end'] + offset_seconds + margin\n",
    "\n",
    "                while speaker_idx < n_speakers:\n",
    "                    turn, _, speaker = diarization_list[speaker_idx]\n",
    "\n",
    "                    if turn.start <= word_end and turn.end >= word_start:\n",
    "                        # Add word without modifications\n",
    "                        segment_text.append(word['word'])\n",
    "                        \n",
    "                        # Strip here for individual word storage\n",
    "                        word['word'] = word['word'].strip()\n",
    "                        segment_words.append(word)\n",
    "\n",
    "                        if turn.end <= word_end:\n",
    "                            speaker_idx += 1\n",
    "\n",
    "                        break\n",
    "                    elif turn.end < word_start:\n",
    "                        speaker_idx += 1\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            if segment_text:\n",
    "                combined_text = ''.join(segment_text)\n",
    "                cleaned_text = re.sub('  ', ' ', combined_text).strip()\n",
    "                new_segment = {\n",
    "                    'start': segment_start - offset_seconds,\n",
    "                    'end': segment_end - offset_seconds,\n",
    "                    'speaker': speaker,\n",
    "                    'text': cleaned_text,\n",
    "                    'words': segment_words\n",
    "                }\n",
    "                final_segments.append(new_segment)\n",
    "\n",
    "        time_merging_end = time.time()\n",
    "        print(\n",
    "            f\"Finished with merging, took {time_merging_end - time_diraization_end:.5} seconds\"\n",
    "        )\n",
    "        segments = final_segments\n",
    "        # Make output\n",
    "        output = []  # Initialize an empty list for the output\n",
    "\n",
    "        # Initialize the first group with the first segment\n",
    "        current_group = {\n",
    "            'start': str(segments[0][\"start\"]),\n",
    "            'end': str(segments[0][\"end\"]),\n",
    "            'speaker': segments[0][\"speaker\"],\n",
    "            'text': segments[0][\"text\"],\n",
    "            'words': segments[0][\"words\"]\n",
    "        }\n",
    "\n",
    "        for i in range(1, len(segments)):\n",
    "            # Calculate time gap between consecutive segments\n",
    "            time_gap = segments[i][\"start\"] - segments[i - 1][\"end\"]\n",
    "\n",
    "            # If the current segment's speaker is the same as the previous segment's speaker, and the time gap is less than or equal to 2 seconds, group them\n",
    "            if segments[i][\"speaker\"] == segments[\n",
    "                    i - 1][\"speaker\"] and time_gap <= 2 and group_segments:\n",
    "                current_group[\"end\"] = str(segments[i][\"end\"])\n",
    "                current_group[\"text\"] += \" \" + segments[i][\"text\"]\n",
    "                current_group[\"words\"] += segments[i][\"words\"]\n",
    "            else:\n",
    "                # Add the current_group to the output list\n",
    "                output.append(current_group)\n",
    "\n",
    "                # Start a new group with the current segment\n",
    "                current_group = {\n",
    "                    'start': str(segments[i][\"start\"]),\n",
    "                    'end': str(segments[i][\"end\"]),\n",
    "                    'speaker': segments[i][\"speaker\"],\n",
    "                    'text': segments[i][\"text\"],\n",
    "                    'words': segments[i][\"words\"]\n",
    "                }\n",
    "\n",
    "        # Add the last group to the output list\n",
    "        output.append(current_group)\n",
    "\n",
    "        time_cleaning_end = time.time()\n",
    "        print(\n",
    "            f\"Finished with cleaning, took {time_cleaning_end - time_merging_end:.5} seconds\"\n",
    "        )\n",
    "        time_end = time.time()\n",
    "        time_diff = time_end - time_start\n",
    "\n",
    "        system_info = f\"\"\"Processing time: {time_diff:.5} seconds\"\"\"\n",
    "        print(system_info)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc055ee9-96f4-47c1-aba0-79bf21813507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/thomasmol/faster-whisper.git@master\n",
      "  Cloning https://github.com/thomasmol/faster-whisper.git (to revision master) to /private/var/folders/04/ysg_dpf16px3f4_bq92dpxww0000gn/T/pip-req-build-elenx0zl\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/thomasmol/faster-whisper.git /private/var/folders/04/ysg_dpf16px3f4_bq92dpxww0000gn/T/pip-req-build-elenx0zl\n",
      "  Resolved https://github.com/thomasmol/faster-whisper.git to commit 23ba656e0b7df8c3d892698c7428f9fc84593496\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting av==10.* (from faster-whisper==0.9.0)\n",
      "  Downloading av-10.0.0-cp311-cp311-macosx_11_0_arm64.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ctranslate2<4,>=3.17 (from faster-whisper==0.9.0)\n",
      "  Downloading ctranslate2-3.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting huggingface_hub>=0.13 (from faster-whisper==0.9.0)\n",
      "  Downloading huggingface_hub-0.19.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tokenizers<0.15,>=0.13 (from faster-whisper==0.9.0)\n",
      "  Downloading tokenizers-0.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "INFO: pip is looking at multiple versions of faster-whisper to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime-gpu<2,>=1.16.0 (from faster-whisper) (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime-gpu<2,>=1.16.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/thomasmol/faster-whisper.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa05714c-0dec-4e5d-81a7-f2ff7bb279de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime-gpu==1.16.0 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime-gpu==1.16.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-gpu==1.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f038739f-0b0a-44f2-9a9d-19e533c6d8a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "failed to find libmagic.  Check your installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmagic\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/videoextractor/packages/api/venv/lib/python3.11/site-packages/magic/__init__.py:209\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\u001b[38;5;241m.\u001b[39mfrom_descriptor(fd)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loader\n\u001b[0;32m--> 209\u001b[0m libmagic \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m magic_t \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorcheck_null\u001b[39m(result, func, args):\n",
      "File \u001b[0;32m~/Workspace/videoextractor/packages/api/venv/lib/python3.11/site-packages/magic/loader.py:49\u001b[0m, in \u001b[0;36mload_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;66;03m# It is better to raise an ImportError since we are importing magic module\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to find libmagic.  Check your installation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: failed to find libmagic.  Check your installation"
     ]
    }
   ],
   "source": [
    "import magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661ffedb-9a68-4316-92a0-80936aed551b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "failed to find libmagic.  Check your installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmagic\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmimetypes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/videoextractor/packages/api/venv/lib/python3.11/site-packages/magic/__init__.py:209\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\u001b[38;5;241m.\u001b[39mfrom_descriptor(fd)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loader\n\u001b[0;32m--> 209\u001b[0m libmagic \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m magic_t \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorcheck_null\u001b[39m(result, func, args):\n",
      "File \u001b[0;32m~/Workspace/videoextractor/packages/api/venv/lib/python3.11/site-packages/magic/loader.py:49\u001b[0m, in \u001b[0;36mload_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;66;03m# It is better to raise an ImportError since we are importing magic module\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to find libmagic.  Check your installation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: failed to find libmagic.  Check your installation"
     ]
    }
   ],
   "source": [
    "from typing import Any, List\n",
    "import base64\n",
    "import contextlib\n",
    "import datetime\n",
    "import json\n",
    "import magic\n",
    "import mimetypes\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import torch\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a73178-76b3-4a89-acb8-9f26ae864f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: python-magic 0.4.27\n",
      "Uninstalling python-magic-0.4.27:\n",
      "  Successfully uninstalled python-magic-0.4.27\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall python-magic -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7587f1-2df5-4d3f-864f-b19485416228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python-magic-bin (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for python-magic-bin\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dee7c54-b9df-48b4-bad5-cea5527148c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python-magic-bin (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for python-magic-bin\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e4d1b0-48e5-47db-a521-d55cb0862af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python-magic-bin (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for python-magic-bin\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd30d6-ab4e-4279-bc9e-98b51bd4b0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
